{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 100)          0           input_1[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            101         multiply_1[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import shap, keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=1000)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=100).astype(\"float64\")\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=100).astype(\"float64\")\n",
    "# create the model\n",
    "embedding_vector_length = 32\n",
    "inp = keras.layers.Input(shape=(100,))\n",
    "mult = keras.layers.Multiply()([inp, inp])\n",
    "out = keras.layers.Dense(1)(mult)\n",
    "model = keras.models.Model(inputs=[inp], outputs=out)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inds = np.random.choice(X_train.shape[0], 3, replace=False)\n",
    "data = X_train[inds,:]\n",
    "test_in = X_test[10:11,:]\n",
    "e = shap.DeepExplainer((model.layers[0].input, model.layers[-1].input), data)\n",
    "shap_values = e.shap_values(test_in)\n",
    "sums = np.array([shap_values[i].sum() for i in range(len(shap_values))])\n",
    "sess = tf.keras.backend.get_session()\n",
    "diff = sess.run(model.layers[-1].input, feed_dict={model.layers[0].input: test_in})[0,:] - \\\n",
    "    sess.run(model.layers[-1].input, feed_dict={model.layers[0].input: data}).mean(0)\n",
    "assert np.allclose(sums, diff, atol=1e-06), \"Sum of SHAP values does not match difference!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
