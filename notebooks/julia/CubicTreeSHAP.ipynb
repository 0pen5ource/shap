{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cubic Tree SHAP\n",
    "\n",
    "Here we demonstrate an algorithm for exactly computing the SHAP value of a decision tree in $O(LD^2)$ running time, where $L$ is the number of leaves in the tree and $D$ is the maximum depth of the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree SHAP algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tree_shap! (generic function with 7 methods)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data we keep about our decision path\n",
    "# note that pweight is included for convenience and is not tied with the other attributes\n",
    "# the pweight of the i'th path element is the permuation weight of paths with i-1 ones in them\n",
    "type PathElement\n",
    "    feature_index\n",
    "    zero_fraction\n",
    "    one_fraction\n",
    "    pweight\n",
    "end\n",
    "\n",
    "# extend our decision path with a fraction of one and zero extensions\n",
    "function extend_path!(unique_path, unique_depth, zero_fraction, one_fraction, feature_index)\n",
    "    unique_path[unique_depth+1] = PathElement(feature_index, zero_fraction, one_fraction, unique_depth == 0 ? 1 : 0)\n",
    "    for i in unique_depth:-1:1\n",
    "        unique_path[i+1].pweight += one_fraction*unique_path[i].pweight*i/(unique_depth+1)\n",
    "        unique_path[i].pweight = zero_fraction*unique_path[i].pweight*(unique_depth-i+1)/(unique_depth+1)\n",
    "    end\n",
    "end\n",
    "\n",
    "# undo a previous extension of the decision path\n",
    "function unwind_path!(unique_path, unique_depth, path_index)\n",
    "    one_fraction = unique_path[path_index].one_fraction\n",
    "    zero_fraction = unique_path[path_index].zero_fraction\n",
    "    next_one_portion = unique_path[unique_depth+1].pweight\n",
    "    \n",
    "    for i in unique_depth:-1:1\n",
    "        if one_fraction != 0\n",
    "            tmp = unique_path[i].pweight\n",
    "            unique_path[i].pweight = next_one_portion*(unique_depth+1)/(i*one_fraction)\n",
    "            next_one_portion = tmp - unique_path[i].pweight*zero_fraction*(unique_depth-i+1)/(unique_depth+1)\n",
    "        else\n",
    "            unique_path[i].pweight = (unique_path[i].pweight*(unique_depth+1))/(zero_fraction*(unique_depth-i+1))\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    for i in path_index:unique_depth\n",
    "        unique_path[i].feature_index = unique_path[i+1].feature_index\n",
    "        unique_path[i].zero_fraction = unique_path[i+1].zero_fraction\n",
    "        unique_path[i].one_fraction = unique_path[i+1].one_fraction\n",
    "    end\n",
    "end\n",
    "\n",
    "# determine what the total permuation weight would be if we unwound a previous extension in the decision path\n",
    "function unwound_path_sum(unique_path, unique_depth, path_index)\n",
    "    one_fraction = unique_path[path_index].one_fraction\n",
    "    zero_fraction = unique_path[path_index].zero_fraction\n",
    "    next_one_portion = unique_path[unique_depth+1].pweight\n",
    "    total = 0\n",
    "    for i in unique_depth:-1:1  \n",
    "        if one_fraction != 0\n",
    "            tmp = next_one_portion*(unique_depth+1)/(i*one_fraction)\n",
    "            total += tmp\n",
    "            next_one_portion = unique_path[i].pweight - tmp*zero_fraction*((unique_depth-i+1)/(unique_depth+1))\n",
    "        else\n",
    "            total += (unique_path[i].pweight/zero_fraction)/((unique_depth-i+1)/(unique_depth+1))\n",
    "        end\n",
    "    end\n",
    "    total\n",
    "end\n",
    "\n",
    "# recursive computation of SHAP values for a decision tree\n",
    "function tree_shap!(phi, x, tree_nodes, node_index=1, unique_depth=0, parent_unique_path=PathElement[],\n",
    "                    parent_zero_fraction=1, parent_one_fraction=1, parent_feature_index=0)\n",
    "    node = tree_nodes[node_index]\n",
    "    \n",
    "    # extend the unique path\n",
    "    unique_path = Array(PathElement, unique_depth+1)\n",
    "    unique_path[1:unique_depth] = deepcopy(parent_unique_path[1:unique_depth])\n",
    "    extend_path!(unique_path, unique_depth, parent_zero_fraction, parent_one_fraction, parent_feature_index)\n",
    "    \n",
    "    # leaf node\n",
    "    if node.feature_index == 0\n",
    "        for i in 2:unique_depth+1\n",
    "            w = unwound_path_sum(unique_path, unique_depth, i)\n",
    "            el = unique_path[i]\n",
    "            phi[el.feature_index] += w*(el.one_fraction-el.zero_fraction)*node.value\n",
    "        end\n",
    "    \n",
    "    # internal node\n",
    "    else\n",
    "        # find which branch is \"hot\" (meaning x would follow it)\n",
    "        hot_index = 0\n",
    "        if x[node.feature_index] == nothing\n",
    "            hot_index = node.missing_index\n",
    "        elseif x[node.feature_index] < node.value\n",
    "            hot_index = node.yes_index\n",
    "        else\n",
    "            hot_index = node.no_index\n",
    "        end\n",
    "        cold_index = (hot_index == node.yes_index ? node.no_index : node.yes_index)\n",
    "        hot_zero_fraction = tree_nodes[hot_index].cover/node.cover\n",
    "        cold_zero_fraction = tree_nodes[cold_index].cover/node.cover\n",
    "        incoming_zero_fraction = incoming_one_fraction = 1\n",
    "        \n",
    "        # see if we have already split on this feature, if so we undo that split so we can redo it for this node\n",
    "        path_index = findfirst([e.feature_index for e in unique_path], node.feature_index)\n",
    "        if path_index != 0\n",
    "            incoming_zero_fraction = unique_path[path_index].zero_fraction\n",
    "            incoming_one_fraction = unique_path[path_index].one_fraction\n",
    "            unwind_path!(unique_path, unique_depth, path_index)\n",
    "            unique_depth -= 1\n",
    "        end\n",
    "        \n",
    "        tree_shap!(\n",
    "            phi, x, tree_nodes, hot_index, unique_depth+1, unique_path,\n",
    "            hot_zero_fraction*incoming_zero_fraction, incoming_one_fraction, node.feature_index\n",
    "        )\n",
    "        tree_shap!(\n",
    "            phi, x, tree_nodes, cold_index, unique_depth+1, unique_path,\n",
    "            cold_zero_fraction*incoming_zero_fraction, 0, node.feature_index\n",
    "        )\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supporting evaluation and comparison code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions to run the SHAP algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xgboost_shap_data (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using XGBoost\n",
    "\n",
    "function xgboost_shap(bst, x)\n",
    "    global weight_cache = Dict()\n",
    "    phi = zeros(length(x))\n",
    "    data = XGBoost.XGBoosterDumpModel(bst.handle, \"\", 1)\n",
    "    phi0 = 0.0\n",
    "    base_score = 0.0\n",
    "    for tree_num in 1:length(data)\n",
    "        nodes = parse_xgboost_tree(unsafe_string(data[tree_num]))\n",
    "        \n",
    "        # find the base_score of the model using the first tree\n",
    "        if tree_num == 1\n",
    "            tree_out = eval_tree(x, nodes)\n",
    "            model_out = predict(bst, reshape(x, 1, length(x)), ntree_limit=1)[1]\n",
    "            base_score = model_out - tree_out\n",
    "        end\n",
    "                \n",
    "        phi0 += cond_expectation([], x, nodes)[1]\n",
    "        tree_shap!(phi, x, nodes)\n",
    "    end\n",
    "    phi0+base_score,phi\n",
    "end\n",
    "function xgboost_shap_data(data, x)\n",
    "    global weight_cache = Dict()\n",
    "    phi = zeros(length(x))\n",
    "    #data = XGBoost.XGBoosterDumpModel(bst.handle, \"\", 1)\n",
    "    phi0 = 0.0\n",
    "    base_score = 0.0\n",
    "    for tree_num in 1:length(data)\n",
    "        nodes = parse_xgboost_tree(data[tree_num])\n",
    "                        #println(nodes)\n",
    "        # find the base_score of the model using the first tree\n",
    "#         if tree_num == 1\n",
    "#             tree_out = eval_tree(x, nodes)\n",
    "#             model_out = predict(bst, reshape(x, 1, length(x)), ntree_limit=1)[1]\n",
    "#             base_score = model_out - tree_out\n",
    "#         end\n",
    "                \n",
    "        #phi0 += cond_expectation([], x, nodes)[1]\n",
    "        tree_shap!(phi, x, nodes)\n",
    "    end\n",
    "    #phi0+base_score,\n",
    "    phi\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to build a Julia representation of the XGBoost trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m\u001b[32mTest Passed\n",
       "\u001b[0m  Expression: all(nodes .== [TreeNode(2,0.210065,2,3,2,100),TreeNode(1,1.14837,4,5,4,59),TreeNode(3,-1.61475,6,7,6,41),TreeNode(0,0.0268182,0,0,0,53),TreeNode(0,-0.0672221,0,0,0,6),TreeNode(0,0.0641373,0,0,0,1),TreeNode(0,-0.0436476,0,0,0,40)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type TreeNode\n",
    "    feature_index\n",
    "    value\n",
    "    yes_index\n",
    "    no_index\n",
    "    missing_index\n",
    "    cover\n",
    "end\n",
    "\n",
    "function parse_xgboost_tree(tree_str)\n",
    "    lines = strip.(split(tree_str, '\\n'))\n",
    "    nodes = Array(TreeNode, length(lines)-1) # ignore the blank line at the end\n",
    "    internal_regex = r\"([0-9]+):\\[f([0-9]+)<([-+e0-9.]+)\\] yes=([0-9]+),no=([0-9]+),missing=([0-9]+),gain=[-e+0-9.]+,cover=([0-9]+)\"\n",
    "    leaf_regex = r\"([0-9]+):leaf=([-e+0-9.]+),cover=([0-9]+)\"\n",
    "    for i in 1:length(lines)-1\n",
    "        m = match(internal_regex, lines[i])\n",
    "        if m != nothing\n",
    "            index = parse(Int64, m.captures[1])+1\n",
    "            feature_index = parse(Int64, m.captures[2])+1\n",
    "            split_val = parse(Float64, m.captures[3])\n",
    "            yes_index = parse(Int64, m.captures[4])+1\n",
    "            no_index = parse(Int64, m.captures[5])+1\n",
    "            missing_index = parse(Int64, m.captures[6])+1\n",
    "            cover = parse(Int64, m.captures[7])\n",
    "            nodes[index] = TreeNode(feature_index, split_val, yes_index, no_index, missing_index, cover)\n",
    "        else\n",
    "            m = match(leaf_regex, lines[i])\n",
    "            index = parse(Int64, m.captures[1])+1\n",
    "            leaf_val = parse(Float64, m.captures[2])\n",
    "            cover = parse(Int64, m.captures[3])\n",
    "            nodes[index] = TreeNode(0, leaf_val, 0, 0, 0, cover)\n",
    "        end\n",
    "    end\n",
    "    nodes\n",
    "end\n",
    "\n",
    "using Base.Test\n",
    "import Base.==\n",
    "\n",
    "function ==(x::TreeNode, y::TreeNode)\n",
    "    x.feature_index == y.feature_index\n",
    "end\n",
    "\n",
    "tree_str = \"0:[f1<0.210065] yes=1,no=2,missing=1,gain=7.70125,cover=100\\n\\t1:[f0<1.14837] yes=3,no=4,missing=3,gain=5.454,cover=59\\n\\t\\t3:leaf=0.0268182,cover=53\\n\\t\\t4:leaf=-0.0672221,cover=6\\n\\t2:[f2<-1.61475] yes=5,no=6,missing=5,gain=2.06263,cover=41\\n\\t\\t5:leaf=0.0641373,cover=1\\n\\t\\t6:leaf=-0.0436476,cover=40\\n\"\n",
    "nodes = parse_xgboost_tree(tree_str)\n",
    "\n",
    "@test all(nodes .== [\n",
    "    TreeNode(2,0.210065,2,3,2,100),\n",
    "    TreeNode(1,1.14837,4,5,4,59),\n",
    "    TreeNode(3,-1.61475,6,7,6,41),\n",
    "    TreeNode(0,0.0268182,0,0,0,53),\n",
    "    TreeNode(0,-0.0672221,0,0,0,6),\n",
    "    TreeNode(0,0.0641373,0,0,0,1),\n",
    "    TreeNode(0,-0.0436476,0,0,0,40)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential time exact algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_tree (generic function with 3 methods)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the value of the tree for a given x\n",
    "function eval_tree(x, tree_nodes, node_index=1, missing_value=nothing)\n",
    "    node = tree_nodes[node_index]\n",
    "    if node.feature_index == 0\n",
    "        return node.value\n",
    "    else\n",
    "        if x[node.feature_index] == missing_value\n",
    "            return eval_tree(x, tree_nodes, node.missing_index, nothing)\n",
    "        elseif x[node.feature_index] < node.value\n",
    "            return eval_tree(x, tree_nodes, node.yes_index, nothing)\n",
    "        else\n",
    "            return eval_tree(x, tree_nodes, node.no_index, nothing)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brute_force_phi_data (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Iterators\n",
    "\n",
    "# compute the expectation of the tree output conditioned on the variables x_S\n",
    "function cond_expectation(S, x, tree_nodes, node_index=1, missing_value=nothing, weight=1.0)\n",
    "    node = tree_nodes[node_index]\n",
    "    val = 0.0\n",
    "    sum_weight = 0\n",
    "    if node.feature_index == 0\n",
    "        val = node.value\n",
    "        sum_weight = weight\n",
    "    elseif node.feature_index in S\n",
    "        if x[node.feature_index] == missing_value\n",
    "            val,sum_weight = cond_expectation(S, x, tree_nodes, node.missing_index, missing_value, weight)\n",
    "        elseif x[node.feature_index] < node.value\n",
    "            val,sum_weight = cond_expectation(S, x, tree_nodes, node.yes_index, missing_value, weight)\n",
    "        else\n",
    "            val,sum_weight = cond_expectation(S, x, tree_nodes, node.no_index, missing_value, weight)\n",
    "        end\n",
    "    else\n",
    "        @assert node.missing_index == node.no_index || node.missing_index == node.yes_index\n",
    "        val1,weight1 = cond_expectation(S, x, tree_nodes, node.yes_index, missing_value, weight*(tree_nodes[node.yes_index].cover/node.cover))\n",
    "        val2,weight2 = cond_expectation(S, x, tree_nodes, node.no_index, missing_value, weight*(tree_nodes[node.no_index].cover/node.cover))\n",
    "        sum_weight = weight1 + weight2\n",
    "        val = (weight1*val1 + weight2*val2)/sum_weight\n",
    "    end\n",
    "    val,sum_weight\n",
    "end\n",
    "\n",
    "function shapley_weight(M, s)\n",
    "    factorial(s)*factorial(M-s-1)/factorial(M)\n",
    "end\n",
    "\n",
    "# uses the conditional expectation algorithm to brute force compute a SHAP value\n",
    "function brute_force_phi(bst, x, i)\n",
    "    brute_force_phi_data(unsafe_string.(XGBoost.XGBoosterDumpModel(bst.handle, \"\", 1)), x, i)\n",
    "end\n",
    "\n",
    "function brute_force_phi_data(data, x, i)\n",
    "    phi = 0.0\n",
    "\n",
    "    for tree_num in 1:length(data)\n",
    "        nodes = parse_xgboost_tree(data[tree_num])\n",
    "        \n",
    "        for subset in subsets(setdiff(1:length(x), [i]))\n",
    "            val1,weight1 = cond_expectation(union(subset, [i]), x, nodes)\n",
    "            val2,weight2 = cond_expectation(subset, x, nodes)\n",
    "            w = shapley_weight(length(x), length(subset))\n",
    "            phi += w*(val1-val2)\n",
    "        end\n",
    "    end\n",
    "    phi\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "verify_match (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function verify_match(data, x)\n",
    "    phi1 = [brute_force_phi_data(data, x, i) for i in 1:length(x)]\n",
    "    phi2 = xgboost_shap_data(data, x)\n",
    "    println(\"brute_force = $phi1\")\n",
    "    println(\"fast_method = $phi2\")\n",
    "    if norm(phi1 .- phi2) > 1e-8 || isnan(norm(phi1 .- phi2))\n",
    "        @assert false\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brute_force = [0.375,0.375,0.0,0.0]\n",
      "fast_method = [0.375,0.375,0.0,0.0]\n",
      "brute_force = [0.125,-0.375,0.0,0.0]\n",
      "fast_method = [0.125,-0.375,0.0,0.0]\n",
      "brute_force = [0.5,0.0,0.0,0.0]\n",
      "fast_method = [0.5,0.0,0.0,0.0]\n",
      "brute_force = [0.75,0.0,0.0,0.0]\n",
      "fast_method = [0.75,0.0,0.0,0.0]\n",
      "brute_force = [0.5,0.0,0.0,0.0]\n",
      "fast_method = [0.5,0.0,0.0,0.0]\n",
      "brute_force = [0.4,0.0,0.0,0.0]\n",
      "fast_method = [0.4,-1.38778e-17,0.0,0.0]\n",
      "brute_force = [0.0833333,0.0,0.0833333,-0.291667]\n",
      "fast_method = [0.0833333,0.0,0.0833333,-0.291667]\n"
     ]
    }
   ],
   "source": [
    "x = ones(4)\n",
    "data = [\"0:[f0<0.5] yes=1,no=2,missing=1,gain=5.95771,cover=100\\n\\t1:[f1<0.5] yes=3,no=4,missing=3,gain=4.72408,cover=50\\n\\t\\t3:leaf=0,cover=25\\n\\t\\t4:leaf=0,cover=25\\n\\t2:[f1<0.5] yes=5,no=6,missing=5,gain=2.30706,cover=50\\n\\t\\t5:leaf=0,cover=25\\n\\t\\t6:leaf=1,cover=25\\n\"]\n",
    "verify_match(data, x)\n",
    "\n",
    "data = [\"0:[f0<0.5] yes=1,no=2,missing=1,gain=5.95771,cover=100\\n\\t1:[f1<0.5] yes=3,no=4,missing=3,gain=4.72408,cover=50\\n\\t\\t3:leaf=0,cover=25\\n\\t\\t4:leaf=0,cover=25\\n\\t2:[f1<0.5] yes=5,no=6,missing=5,gain=2.30706,cover=50\\n\\t\\t5:leaf=1,cover=25\\n\\t\\t6:leaf=0,cover=25\\n\"];\n",
    "verify_match(data, x)\n",
    "\n",
    "data = [\"0:[f0<0.5] yes=1,no=2,missing=1,gain=5.95771,cover=100\\n\\t1:[f1<0.5] yes=3,no=4,missing=3,gain=4.72408,cover=50\\n\\t\\t3:leaf=0,cover=25\\n\\t\\t4:leaf=0,cover=25\\n\\t2:[f0<0.4] yes=5,no=6,missing=5,gain=2.30706,cover=50\\n\\t\\t5:leaf=1,cover=25\\n\\t\\t6:leaf=1,cover=25\\n\"]\n",
    "verify_match(data, x)\n",
    "\n",
    "data = [\"0:[f0<0.0547004] yes=1,no=2,missing=1,gain=6.41592,cover=100\\n\\t1:[f0<-0.1] yes=3,no=4,missing=3,gain=7.23454,cover=50\\n\\t\\t3:leaf=0,cover=25\\n\\t\\t4:leaf=0,cover=25\\n\\t2:[f0<0.5] yes=5,no=6,missing=5,gain=9.11159,cover=50\\n\\t\\t5:leaf=0,cover=25\\n\\t\\t6:leaf=1,cover=25\\n\"];\n",
    "verify_match(data, x)\n",
    "\n",
    "data = [\"0:[f0<0.0547004] yes=1,no=2,missing=1,gain=6.41592,cover=100\\n\\t1:[f0<-0.1] yes=3,no=4,missing=3,gain=7.23454,cover=50\\n\\t\\t3:leaf=1,cover=25\\n\\t\\t4:leaf=0,cover=25\\n\\t2:[f0<0.5] yes=5,no=6,missing=5,gain=9.11159,cover=50\\n\\t\\t5:leaf=0,cover=25\\n\\t\\t6:leaf=1,cover=25\\n\"];\n",
    "verify_match(data, x)\n",
    "\n",
    "data = [\"0:[f0<0.0547004] yes=1,no=2,missing=1,gain=6.41592,cover=100\\n\\t1:[f1<-0.1] yes=3,no=4,missing=3,gain=7.23454,cover=50\\n\\t\\t3:leaf=1,cover=15\\n\\t\\t4:leaf=0,cover=35\\n\\t2:[f1<0.5] yes=5,no=6,missing=5,gain=9.11159,cover=50\\n\\t\\t5:leaf=0,cover=5\\n\\t\\t6:leaf=1,cover=45\\n\"];\n",
    "verify_match(data, x)\n",
    "\n",
    "data = [\"0:[f0<-0.108652] yes=1,no=2,missing=1,gain=9.91912,cover=200\\n\\t1:[f1<-0.0500525] yes=3,no=4,missing=3,gain=7.68742,cover=100\\n\\t\\t3:[f2<-1.18479] yes=7,no=8,missing=7,gain=5.72911,cover=50\\n\\t\\t\\t7:leaf=0,cover=25\\n\\t\\t\\t8:leaf=0,cover=25\\n\\t\\t4:[f2<-0.28887] yes=9,no=10,missing=9,gain=4.89582,cover=50\\n\\t\\t\\t9:leaf=0,cover=25\\n\\t\\t\\t10:leaf=0,cover=25\\n\\t2:[f3<-1.82883] yes=5,no=6,missing=5,gain=5.23317,cover=100\\n\\t\\t5:[f2<0.914076] yes=11,no=12,missing=11,gain=6.40652,cover=50\\n\\t\\t\\t11:leaf=0,cover=25\\n\\t\\t\\t12:leaf=1,cover=25\\n\\t\\t6:[f2<0.914076] yes=13,no=14,missing=13,gain=6.40652,cover=50\\n\\t\\t\\t13:leaf=0,cover=35\\n\\t\\t\\t14:leaf=0,cover=15\\n\"]\n",
    "verify_match(data, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an XGBoost tree model to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:[f1<-1.69235] yes=1,no=2,missing=1,gain=15.3372,cover=1000\n",
      "\t1:[f7<0.161436] yes=3,no=4,missing=3,gain=8.69375,cover=35\n",
      "\t\t3:[f2<0.699213] yes=7,no=8,missing=7,gain=3.15086,cover=23\n",
      "\t\t\t7:leaf=-0.0282265,cover=16\n",
      "\t\t\t8:leaf=0.0478976,cover=7\n",
      "\t\t4:[f1<-1.72871] yes=9,no=10,missing=9,gain=3.38603,cover=12\n",
      "\t\t\t9:leaf=0.119984,cover=10\n",
      "\t\t\t10:leaf=-0.0147658,cover=2\n",
      "\t2:[f6<-0.509197] yes=5,no=6,missing=5,gain=12.2108,cover=965\n",
      "\t\t5:[f6<-2.61395] yes=11,no=12,missing=11,gain=8.48565,cover=273\n",
      "\t\t\t11:leaf=0.101897,cover=5\n",
      "\t\t\t12:leaf=-0.0185253,cover=268\n",
      "\t\t6:[f2<1.77262] yes=13,no=14,missing=13,gain=6.6369,cover=692\n",
      "\t\t\t13:leaf=-0.0390368,cover=668\n",
      "\t\t\t14:leaf=-0.0921749,cover=24\n",
      "\n",
      "brute_force = [0.0,-0.00371667,0.00196208,0.0,0.0,0.0,-0.00656882,0.000976718,0.0,0.0]\n",
      "fast_method = [0.0,-0.00371667,0.00196208,0.0,0.0,0.0,-0.00656882,0.000976718,0.0,0.0]\n"
     ]
    }
   ],
   "source": [
    "using Iterators\n",
    "using XGBoost\n",
    "\n",
    "N = 1000\n",
    "M = 10\n",
    "X = randn(N,M)\n",
    "x = randn(M)\n",
    "y = randn(N)\n",
    "dtrain = DMatrix(X,label=y)\n",
    "bst = xgboost(dtrain, 1, param=Dict(\"max_depth\"=>3, \"objective\"=>\"reg:linear\", \"eta\"=>.1, \"base_score\"=>0.3), silent=true)\n",
    "\n",
    "data=unsafe_string.(XGBoost.XGBoosterDumpModel(bst.handle, \"\", 1))\n",
    "x = ones(M)\n",
    "println(data[1])\n",
    "verify_match(data, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
